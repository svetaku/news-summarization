{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-18T19:24:25.367913Z",
     "iopub.status.busy": "2024-04-18T19:24:25.367236Z",
     "iopub.status.idle": "2024-04-18T19:24:37.176822Z",
     "shell.execute_reply": "2024-04-18T19:24:37.175847Z",
     "shell.execute_reply.started": "2024-04-18T19:24:25.367877Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, \\\n",
    "    Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq, get_scheduler\n",
    "import evaluate\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\svvlk\\\\Documents\\\\python\\\\personal\\\\news_sum'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Not scanning for jupyter notebooks.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\svvlk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\svvlk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\svvlk\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\\pipreqs.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\svvlk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pipreqs\\pipreqs.py\", line 609, in main\n",
      "    init(args)\n",
      "  File \"C:\\Users\\svvlk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pipreqs\\pipreqs.py\", line 533, in init\n",
      "    candidates = get_all_imports(\n",
      "  File \"C:\\Users\\svvlk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pipreqs\\pipreqs.py\", line 136, in get_all_imports\n",
      "    contents = read_file_content(file_name, encoding)\n",
      "  File \"C:\\Users\\svvlk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pipreqs\\pipreqs.py\", line 181, in read_file_content\n",
      "    contents = f.read()\n",
      "  File \"C:\\Users\\svvlk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa4 in position 64: invalid start byte\n"
     ]
    }
   ],
   "source": [
    "!pipreqs C:\\\\Users\\\\svvlk\\\\Documents\\\\python\\\\personal\\\\news_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:24:37.179037Z",
     "iopub.status.busy": "2024-04-18T19:24:37.178296Z",
     "iopub.status.idle": "2024-04-18T19:24:37.478054Z",
     "shell.execute_reply": "2024-04-18T19:24:37.477092Z",
     "shell.execute_reply.started": "2024-04-18T19:24:37.178997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4396 entries, 0 to 4513\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   author     4396 non-null   object\n",
      " 1   date       4396 non-null   object\n",
      " 2   headlines  4396 non-null   object\n",
      " 3   read_more  4396 non-null   object\n",
      " 4   text       4396 non-null   object\n",
      " 5   ctext      4396 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 240.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('news_summary.csv', encoding='cp437')\n",
    "data = data.dropna()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:24:37.479897Z",
     "iopub.status.busy": "2024-04-18T19:24:37.479500Z",
     "iopub.status.idle": "2024-04-18T19:24:37.590789Z",
     "shell.execute_reply": "2024-04-18T19:24:37.589902Z",
     "shell.execute_reply.started": "2024-04-18T19:24:37.479861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean headline length (words): 9.300045495905369\n",
      "Mean text length (words): 342.9438125568699\n"
     ]
    }
   ],
   "source": [
    "# headlines - column containing headlines which will be used as reference summarizations\n",
    "# ctext - column containing full texts of news articles\n",
    "# taking a look at the average lengths of both\n",
    "\n",
    "def length(text):\n",
    "    return len(text.split())\n",
    "\n",
    "print('Mean headline length (words):', data['headlines'].apply(length).mean())\n",
    "print('Mean text length (words):', data['ctext'].apply(length).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:24:51.002795Z",
     "iopub.status.busy": "2024-04-18T19:24:51.001867Z",
     "iopub.status.idle": "2024-04-18T19:24:51.134565Z",
     "shell.execute_reply": "2024-04-18T19:24:51.133596Z",
     "shell.execute_reply.started": "2024-04-18T19:24:51.002760Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['author', 'date', 'headlines', 'read_more', 'text', 'ctext', '__index_level_0__'],\n",
       "        num_rows: 3516\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['author', 'date', 'headlines', 'read_more', 'text', 'ctext', '__index_level_0__'],\n",
       "        num_rows: 439\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['author', 'date', 'headlines', 'read_more', 'text', 'ctext', '__index_level_0__'],\n",
       "        num_rows: 441\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the data into train, val, and test, and converting it into Dataset format\n",
    "\n",
    "train_size = int(0.8 * len(data))\n",
    "val_size = int(0.1 * len(data))\n",
    "test_size = len(data) - train_size - val_size\n",
    "\n",
    "train_data = data[:train_size]\n",
    "val_data = data[train_size:train_size+val_size]\n",
    "test_data = data[train_size+val_size:]\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "val_dataset = Dataset.from_pandas(val_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:26:32.504697Z",
     "iopub.status.busy": "2024-04-18T19:26:32.504301Z",
     "iopub.status.idle": "2024-04-18T19:26:35.195945Z",
     "shell.execute_reply": "2024-04-18T19:26:35.195092Z",
     "shell.execute_reply.started": "2024-04-18T19:26:32.504667Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558ae540304d4c6ba01b339b89790e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/82.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1441d159c34e3a88e0a68206703504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/553 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809f5bfee2f342bca653de61d929bcc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67cdfeb77e247e7a1ab40ad89be79d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# loading the model tokenizer\n",
    "\n",
    "model_checkpoint = \"google/mt5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:26:41.426309Z",
     "iopub.status.busy": "2024-04-18T19:26:41.425936Z",
     "iopub.status.idle": "2024-04-18T19:26:41.432351Z",
     "shell.execute_reply": "2024-04-18T19:26:41.431327Z",
     "shell.execute_reply.started": "2024-04-18T19:26:41.426283Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating tokenization function with length limits for headlines and texts\n",
    "\n",
    "max_input_length = 512\n",
    "max_target_length = 30\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"ctext\"],\n",
    "        max_length=max_input_length,\n",
    "        truncation=True,\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        examples[\"headlines\"], max_length=max_target_length, truncation=True\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:26:51.182699Z",
     "iopub.status.busy": "2024-04-18T19:26:51.181699Z",
     "iopub.status.idle": "2024-04-18T19:26:55.053825Z",
     "shell.execute_reply": "2024-04-18T19:26:55.052908Z",
     "shell.execute_reply.started": "2024-04-18T19:26:51.182666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d5de30d73e4dd3bf5ffad39bc69eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3516 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5683e7808f497c84c3fbfd03e2f533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/439 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135c1882adeb4b03b90332448403c1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/441 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenizing the datasets\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate baseline metrics\n",
    "\n",
    "As a textual data for evaluating the baseline model I will be using 3 first sentences of each article, applying the [ROUGE](https://huggingface.co/spaces/evaluate-metric/rouge) metric, consisting of 'rouge1'(unigram overlap), 'rouge2' (bigram overlap),\n",
    "'rougeL'(longest overlap in a sentence), and 'rougeLsum'(longest overlap in a paragraph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:26:57.697347Z",
     "iopub.status.busy": "2024-04-18T19:26:57.696640Z",
     "iopub.status.idle": "2024-04-18T19:26:58.090988Z",
     "shell.execute_reply": "2024-04-18T19:26:58.090242Z",
     "shell.execute_reply.started": "2024-04-18T19:26:57.697315Z"
    }
   },
   "outputs": [],
   "source": [
    "# loading ROUGE metric\n",
    "\n",
    "rouge_score = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:27:00.140177Z",
     "iopub.status.busy": "2024-04-18T19:27:00.139323Z",
     "iopub.status.idle": "2024-04-18T19:27:00.160791Z",
     "shell.execute_reply": "2024-04-18T19:27:00.159985Z",
     "shell.execute_reply.started": "2024-04-18T19:27:00.140143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From her special numbers to TV?appearances, Bollywood actor Malaika Arora Khan has managed to carve her own identity.\n",
      "The actor, who made her debut in the Hindi film industry with the blockbuster debut opposite Shah Rukh Khan in Chaiyya Chaiyya from Dil Se (1998), is still remembered for the song.\n",
      "However, for trolls, she is a woman first and what matters right now is that she divorced a ?rich man?.\n"
     ]
    }
   ],
   "source": [
    "def three_sentence_summary(text):\n",
    "    return \"\\n\".join(sent_tokenize(text)[:3])\n",
    "\n",
    "\n",
    "print(three_sentence_summary(dataset[\"train\"][1][\"ctext\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:27:03.599249Z",
     "iopub.status.busy": "2024-04-18T19:27:03.598524Z",
     "iopub.status.idle": "2024-04-18T19:27:03.604166Z",
     "shell.execute_reply": "2024-04-18T19:27:03.603200Z",
     "shell.execute_reply.started": "2024-04-18T19:27:03.599207Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_baseline(dataset, metric):\n",
    "    summaries = [three_sentence_summary(text) for text in dataset[\"ctext\"]]\n",
    "    return metric.compute(predictions=summaries, references=dataset[\"headlines\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:27:06.032862Z",
     "iopub.status.busy": "2024-04-18T19:27:06.032500Z",
     "iopub.status.idle": "2024-04-18T19:27:07.494527Z",
     "shell.execute_reply": "2024-04-18T19:27:07.493575Z",
     "shell.execute_reply.started": "2024-04-18T19:27:06.032829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 12.73, 'rouge2': 4.24, 'rougeL': 10.32, 'rougeLsum': 11.15}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting baseline metrics\n",
    "\n",
    "score = evaluate_baseline(dataset[\"validation\"], rouge_score)\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "rouge_dict = dict((rn, round(score[rn] * 100, 2)) for rn in rouge_names)\n",
    "rouge_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:27:15.508905Z",
     "iopub.status.busy": "2024-04-18T19:27:15.507983Z",
     "iopub.status.idle": "2024-04-18T19:27:15.539831Z",
     "shell.execute_reply": "2024-04-18T19:27:15.538848Z",
     "shell.execute_reply.started": "2024-04-18T19:27:15.508853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7413e1d38b1424b83c08a690cd77df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# logging in to Hugging Face Hub\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:27:31.980978Z",
     "iopub.status.busy": "2024-04-18T19:27:31.980268Z",
     "iopub.status.idle": "2024-04-18T19:27:41.233698Z",
     "shell.execute_reply": "2024-04-18T19:27:41.232880Z",
     "shell.execute_reply.started": "2024-04-18T19:27:31.980940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7304b5d71c4188a4ea4934a719d83d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70fd2ce0ae324960aff84351b02f040d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading the pre-trained Seq2Seq model and the data collator\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:27:41.236261Z",
     "iopub.status.busy": "2024-04-18T19:27:41.235490Z",
     "iopub.status.idle": "2024-04-18T19:27:41.330624Z",
     "shell.execute_reply": "2024-04-18T19:27:41.329827Z",
     "shell.execute_reply.started": "2024-04-18T19:27:41.236224Z"
    }
   },
   "outputs": [],
   "source": [
    "# setting arguments \n",
    "\n",
    "batch_size = 8\n",
    "num_train_epochs = 8\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(tokenized_datasets[\"train\"]) // batch_size\n",
    "output_dir = \"mt5-small-finetuned-news-summary-kaggle\"\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5.6e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    predict_with_generate=True,       # calculate ROUGE for every epoch\n",
    "    logging_steps=logging_steps,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:27:46.935297Z",
     "iopub.status.busy": "2024-04-18T19:27:46.934425Z",
     "iopub.status.idle": "2024-04-18T19:27:46.942657Z",
     "shell.execute_reply": "2024-04-18T19:27:46.941558Z",
     "shell.execute_reply.started": "2024-04-18T19:27:46.935264Z"
    }
   },
   "outputs": [],
   "source": [
    "# function for computing ROUGE metrics\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels= np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    result = rouge_score.compute(\n",
    "       predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    result = {key: value * 100 for key, value in result.items()}\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:27:50.167143Z",
     "iopub.status.busy": "2024-04-18T19:27:50.166734Z",
     "iopub.status.idle": "2024-04-18T19:27:50.177798Z",
     "shell.execute_reply": "2024-04-18T19:27:50.176900Z",
     "shell.execute_reply.started": "2024-04-18T19:27:50.167113Z"
    }
   },
   "outputs": [],
   "source": [
    "# removing columns containing strings\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(\n",
    "    dataset[\"train\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:27:53.234161Z",
     "iopub.status.busy": "2024-04-18T19:27:53.233755Z",
     "iopub.status.idle": "2024-04-18T19:27:54.465774Z",
     "shell.execute_reply": "2024-04-18T19:27:54.464730Z",
     "shell.execute_reply.started": "2024-04-18T19:27:53.234129Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining Trainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:27:58.048994Z",
     "iopub.status.busy": "2024-04-18T19:27:58.048257Z",
     "iopub.status.idle": "2024-04-18T19:53:11.949137Z",
     "shell.execute_reply": "2024-04-18T19:53:11.948099Z",
     "shell.execute_reply.started": "2024-04-18T19:27:58.048964Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msvetaku\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20240418_192759-6np5ichc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/svetaku/huggingface/runs/6np5ichc/workspace' target=\"_blank\">likely-voice-5</a></strong> to <a href='https://wandb.ai/svetaku/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/svetaku/huggingface' target=\"_blank\">https://wandb.ai/svetaku/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/svetaku/huggingface/runs/6np5ichc/workspace' target=\"_blank\">https://wandb.ai/svetaku/huggingface/runs/6np5ichc/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1760' max='1760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1760/1760 24:51, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.995636</td>\n",
       "      <td>14.900100</td>\n",
       "      <td>3.361300</td>\n",
       "      <td>13.480000</td>\n",
       "      <td>13.469100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.318300</td>\n",
       "      <td>3.155007</td>\n",
       "      <td>17.977300</td>\n",
       "      <td>5.963800</td>\n",
       "      <td>16.728900</td>\n",
       "      <td>16.679200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8.318300</td>\n",
       "      <td>2.894964</td>\n",
       "      <td>21.325300</td>\n",
       "      <td>7.386600</td>\n",
       "      <td>19.511400</td>\n",
       "      <td>19.516700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.045700</td>\n",
       "      <td>2.808666</td>\n",
       "      <td>25.165200</td>\n",
       "      <td>9.420200</td>\n",
       "      <td>22.734200</td>\n",
       "      <td>22.730200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.045700</td>\n",
       "      <td>2.737482</td>\n",
       "      <td>25.597400</td>\n",
       "      <td>9.412300</td>\n",
       "      <td>23.027100</td>\n",
       "      <td>23.038300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.650500</td>\n",
       "      <td>2.709118</td>\n",
       "      <td>25.927300</td>\n",
       "      <td>9.342100</td>\n",
       "      <td>23.203700</td>\n",
       "      <td>23.165100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.650500</td>\n",
       "      <td>2.694949</td>\n",
       "      <td>26.277700</td>\n",
       "      <td>9.846500</td>\n",
       "      <td>23.653400</td>\n",
       "      <td>23.626200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.517500</td>\n",
       "      <td>2.690750</td>\n",
       "      <td>26.755600</td>\n",
       "      <td>10.122600</td>\n",
       "      <td>24.052000</td>\n",
       "      <td>23.987900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1760, training_loss=4.879849246957085, metrics={'train_runtime': 1513.5565, 'train_samples_per_second': 18.584, 'train_steps_per_second': 1.163, 'total_flos': 1.487267130507264e+16, 'train_loss': 4.879849246957085, 'epoch': 8.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:57:35.480967Z",
     "iopub.status.busy": "2024-04-18T19:57:35.480265Z",
     "iopub.status.idle": "2024-04-18T19:57:56.527839Z",
     "shell.execute_reply": "2024-04-18T19:57:56.526910Z",
     "shell.execute_reply.started": "2024-04-18T19:57:35.480937Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.6907496452331543,\n",
       " 'eval_rouge1': 26.7556,\n",
       " 'eval_rouge2': 10.1226,\n",
       " 'eval_rougeL': 24.052,\n",
       " 'eval_rougeLsum': 23.9879,\n",
       " 'eval_runtime': 21.0318,\n",
       " 'eval_samples_per_second': 20.873,\n",
       " 'eval_steps_per_second': 1.331,\n",
       " 'epoch': 8.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating the model\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pushing to Hugging Face Hub\n",
    "\n",
    "trainer.push_to_hub(commit_message=\"Training complete\", tags=\"summarization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:58:00.876451Z",
     "iopub.status.busy": "2024-04-18T19:58:00.875721Z",
     "iopub.status.idle": "2024-04-18T19:58:35.051310Z",
     "shell.execute_reply": "2024-04-18T19:58:35.050084Z",
     "shell.execute_reply.started": "2024-04-18T19:58:00.876417Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c5c73d3ee0e49bc92be3d37fd7c3747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9f6e6366414d189c73a4f1a1f87e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f85269f3ae844739089aa8d85b3bc9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/861 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b473a000614641935c1510f28e1ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4449490a019d46bb86d4b04071da09ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/16.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9298be64a808454ba34ac6d85a904150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/416 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "hub_model_id = \"svetaku/mt5-small-finetuned-news-summary-kaggle\"\n",
    "summarizer = pipeline(\"summarization\", model=hub_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:58:42.829695Z",
     "iopub.status.busy": "2024-04-18T19:58:42.828912Z",
     "iopub.status.idle": "2024-04-18T19:58:42.836318Z",
     "shell.execute_reply": "2024-04-18T19:58:42.835072Z",
     "shell.execute_reply.started": "2024-04-18T19:58:42.829661Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to get a summary of an article with index idx\n",
    "\n",
    "def print_summary(idx):\n",
    "    review = dataset[\"test\"][idx][\"ctext\"]\n",
    "    title = dataset[\"test\"][idx][\"headlines\"]\n",
    "    summary = summarizer(dataset[\"test\"][idx][\"ctext\"])[0][\"summary_text\"]\n",
    "    print(f\"'>>> Article: {review}'\")\n",
    "    print(f\"\\n'>>> Headline: {title}'\")\n",
    "    print(f\"\\n'>>> Summary: {summary}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T19:59:02.706559Z",
     "iopub.status.busy": "2024-04-18T19:59:02.706197Z",
     "iopub.status.idle": "2024-04-18T19:59:03.457418Z",
     "shell.execute_reply": "2024-04-18T19:59:03.455227Z",
     "shell.execute_reply.started": "2024-04-18T19:59:02.706532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Article: The Indian Army, after consultations with the Defence Ministry, is considering cutting down the numbers of its sahayaks or 'buddies' by 25 percent. This would translate to around 10,000 jawans as there are currently about 40,000 sahayaks in the Indian Army. The move would come in the wake of the controversy over the tasks Indian Army sahayaks perform for officers and junior commissioned officers.Under the army's 'buddy's system, sahayak jawans are attached to officers and junior commissioned officers. A sahayak's tasks include working with the officer or JCO for army-related duties. According to top army sources, the 10,000 sahayak jawans will be replaced by civilians. The civilian substitutes will be employed for officers in static formations such as the Army Headquarters or units in the Delhi area and not operational locations like battalions, brigades and division and corps headquarters. Once their civilian replacements are in the place, the 10,000 sahayak jawans will be moved to army formations across the country. This is perhaps the first step in the dismantling of the army's sahayak or 'buddy' system. The Indian Navy and the Indian Air Force do not have such a system in place.The age-old system recently came into the spotlight after a few jawans posted grievance-filled videos on social media. The videos criticised the buddy system, with the soldiers alleging that they were often made to perform menial tasks for the officers whom they were assigned toáALSO READ: Buddy no more? Army chief supports restricting 'sahayak' system'\n",
      "\n",
      "'>>> Headline: Indian Army considering to reduce its 'sahayaks' by 10,000'\n",
      "\n",
      "'>>> Summary: Delhi Army cuts down numbers of sahayaks'\n"
     ]
    }
   ],
   "source": [
    "print_summary(20)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1895,
     "sourceId": 791838,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
